{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b00a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a29134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file could be found matching with the 'ISCIII/reception.xlsx' filename given.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ISCIII/reception.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 136>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m ISCIII \u001b[38;5;241m=\u001b[39m Homogeneizer(infile_path)\n\u001b[1;32m    135\u001b[0m ISCIII\u001b[38;5;241m.\u001b[39massociate_dict()\n\u001b[0;32m--> 136\u001b[0m \u001b[43mISCIII\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m ISCIII\u001b[38;5;241m.\u001b[39mload_dictionary()\n\u001b[1;32m    138\u001b[0m ISCIII\u001b[38;5;241m.\u001b[39mtranslate_dataframe()\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mHomogeneizer.load_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m tsv_extensions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_extension(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, excel_extensions):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m check_extension(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, odf_extension):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Needs a special package\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124modf\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/relecov-tools-pruebas/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/relecov-tools-pruebas/lib/python3.10/site-packages/pandas/io/excel/_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/relecov-tools-pruebas/lib/python3.10/site-packages/pandas/io/excel/_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/relecov-tools-pruebas/lib/python3.10/site-packages/pandas/io/excel/_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1248\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1253\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1254\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/relecov-tools-pruebas/lib/python3.10/site-packages/pandas/io/common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ISCIII/reception.xlsx'"
     ]
    }
   ],
   "source": [
    "def check_extension(instring, extensions):\n",
    "    \"\"\"Given a file as a string and a list of possible extensions,\n",
    "    returns true if the extension can be found in the file\"\"\"\n",
    "    for extension in extensions:\n",
    "        if instring.endswith(extension):\n",
    "            return True\n",
    "\n",
    "\n",
    "def open_json(json_path):\n",
    "    \"\"\"Load the json file\"\"\"\n",
    "    with open(json_path) as file:\n",
    "        json_dict = json.load(file)\n",
    "    return json_dict\n",
    "\n",
    "\n",
    "class Homogeneizer:\n",
    "    \"\"\"Homogeneizer object\"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.dictionary_path = None\n",
    "        self.dicionary = None\n",
    "        self.centre = None\n",
    "        self.dataframe = None\n",
    "\n",
    "        # To Do: replace string with local file system for testing\n",
    "        # Header path can be found in conf/configuration.json\n",
    "\n",
    "        header_path = \"Schemas/configuration.json\"\n",
    "        self.translated_dataframe = pd.DataFrame(\n",
    "            columns=open_json(header_path)[\"new_table_headers\"]\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def associate_dict(self):\n",
    "        \"\"\"Detect the origin centre of the metadata, and finds the corresponding json file to use\"\"\"\n",
    "\n",
    "        # Check name of the file attribute of the object\n",
    "        # Check schema with all centres and find their json\n",
    "        # associate centre and json with object\n",
    "        # raise error when in doubt\n",
    "        # must check on schema/institution_schemas\n",
    "\n",
    "        path_to_institution_json = \"Schemas/institution_to_schema.json\"\n",
    "\n",
    "        detected = []\n",
    "        institution_dict = open_json(path_to_institution_json)\n",
    "\n",
    "        for key in institution_dict.keys():\n",
    "            # cap insensitive\n",
    "            print(self.filename.split(\"/\")[-1].lower())\n",
    "            if key.lower() in self.filename.split(\"/\")[-1].lower():\n",
    "                detected.append(institution_dict[key])\n",
    "\n",
    "        if len(set(detected)) == 0:\n",
    "            print(f\"No file could be found matching with the '{self.filename}' filename given.\")\n",
    "            \n",
    "        elif len(set(detected)) > 1:\n",
    "            print(\"some problems arised!!!\")  # change this to an elegant form\n",
    "            sys.exit()  # maybe check which ones are being mixed or when none is being found\n",
    "        else:\n",
    "            self.dictionary_path = detected[0]  # first item, they are all equal\n",
    "            print(f\"JSON file found successfully: {self.dictionary_path}\")  # delete this after testing\n",
    "\n",
    "        return\n",
    "\n",
    "    def load_dataframe(self):\n",
    "        \"\"\"Detect possible extensions for the metadata file\n",
    "        Open it into a dataframe\"\"\"\n",
    "\n",
    "        excel_extensions = [\".xlsx\", \".xls\", \".xlsm\", \".xlsb\"]\n",
    "        odf_extension = [\".odf\"]\n",
    "        csv_extensions = [\".csv\"]\n",
    "        tsv_extensions = [\".tsv\"]\n",
    "\n",
    "        if check_extension(self.filename, excel_extensions):\n",
    "            self.dataframe = pd.read_excel(self.filename, header=0)\n",
    "        elif check_extension(self.filename, odf_extension):\n",
    "            # Needs a special package\n",
    "            self.dataframe = pd.read_excel(self.filename, engine=\"odf\", header=0)\n",
    "        elif check_extension(self.filename, csv_extensions):\n",
    "            self.dataframe = pd.read_csv(self.filename, sep=\",\", header=0)\n",
    "        elif check_extension(self.filename, tsv_extensions):\n",
    "            self.dataframe = pd.read_csv(self.filename, sep=\"\\t\", header=0)\n",
    "\n",
    "        return\n",
    "\n",
    "    def load_dictionary(self):\n",
    "        \"\"\"Load the corresponding dictionary\"\"\"\n",
    "\n",
    "        # To Do: replace string with local file system for testing\n",
    "        path_to_tools = \"\"\n",
    "        dict_path = path_to_tools + \"Schemas/\" + self.dictionary_path\n",
    "        self.dictionary = open_json(dict_path)\n",
    "        return\n",
    "\n",
    "    def translate_dataframe(self):\n",
    "        \"\"\"Use the corresponding dictionary to translate the df\"\"\"\n",
    "        # if dictionary is \"none\" or similar, do nothing\n",
    "\n",
    "        for key, value in self.dictionary[\"equivalence\"].items():\n",
    "            if len(value) == 0:\n",
    "                print(f\"Found empty equivalence in the '{self.dictionary_path}' schema: '{key}'\")\n",
    "            elif value in self.dataframe.columns:\n",
    "                self.translated_dataframe[key] = self.dataframe[value]\n",
    "            else:\n",
    "                print(f\"Column '{value}' indicated in the '{self.dictionary_path}' schema could not be found.\")\n",
    "\n",
    "        for key, value in self.dictionary[\"constants\"].items():\n",
    "            if key in self.translated_dataframe.columns:\n",
    "                self.translated_dataframe[key] = value\n",
    "            else:\n",
    "                print(f\"Value '{key}' in schema not found in the resulting dataframe\")\n",
    "            \n",
    "\n",
    "        return\n",
    "\n",
    "    def verify_translated_dataframe(self):\n",
    "        \"\"\"Checks if the dataframe holds all the needed values for the relecov tools suite\"\"\"\n",
    "        \n",
    "        if self.dataframe.shape[0] != self.translated_dataframe.shape[0]:\n",
    "            print(\"Different number of rows after translation\")\n",
    "        else:\n",
    "            print(\"Same number of rows after translation\")\n",
    "        \n",
    "        pass\n",
    "        return\n",
    "\n",
    "    def export_translated_dataframe(self):        \n",
    "        pass\n",
    "        return\n",
    "    \n",
    "\n",
    "infile_path = \"Input/ISCIII_reception.xlsx\"\n",
    "ISCIII = Homogeneizer(infile_path)\n",
    "ISCIII.associate_dict()\n",
    "ISCIII.load_dataframe()\n",
    "ISCIII.load_dictionary()\n",
    "ISCIII.translate_dataframe()\n",
    "ISCIII.verify_translated_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c9b22",
   "metadata": {},
   "source": [
    "# Schema template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc6e71",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9eaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0072039",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b509b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infile = \"Input/ISCIII_reception.xlsx\"\n",
    "pd.read_excel(infile, sheet_name=\"Datos\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1341ef2",
   "metadata": {},
   "source": [
    "## General schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f6a6e",
   "metadata": {},
   "source": [
    "### Funcionamiento básico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0083b4b",
   "metadata": {},
   "source": [
    "* Recepción del archivo\n",
    "* Detección del laboratorio del que se trata\n",
    "    * Loop por las claves del diccionario de laboratorios, si se detecta uno, se toma por ese\n",
    "    * En caso de no encontrar ninguna, usar questionnaire para que indique cuál es? **O RAISE ERROR**\n",
    "    * En caso de encontrar varias, usar questionnaire para seleccionar cuál es?\n",
    "* Selección del _json_file_path_ usando el diccionario\n",
    "* Dos opciones:\n",
    "    * Modificar la dataframe para hacerla la dataframe final\n",
    "    * Crear la dataframe final e ir rellenándola con la dataframe inicial\n",
    "* Profit\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_dict = {\n",
    "            \"lab_name\" : \"json_file_path\",\n",
    "            \"lab2_name\" : \"json_file_path\",\n",
    "            \"lab3_name\" : \"json_file_path\",\n",
    "            \"lab4_name\" : None,\n",
    "            }\n",
    "\n",
    "term_dict = {\n",
    "    \"equivalences\" : {\"termino_final\" : \"termino_inicial\", \n",
    "                      \"termino_final_2\" : \"termino_inicial_2\"},\n",
    "    \"constants\" : {\"termino_final\" : \"valor constante\"},\n",
    "    \"empty\" : [\"terminos_finales_no_incluidos\"],\n",
    "    \"outer\" : {\"termino_final\" : {\"localización\" : \"término_inicial\"}}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_format = [\n",
    "    \"Public Health sample id (SIVIES)\",\n",
    "    \"Sample ID given by originating laboratory\",\n",
    "    \"Sample ID given by the submitting laboratory\",\n",
    "    \"Sample ID given in the microbiology lab\",\n",
    "    \"Sample ID given if multiple rna-extraction or passages\",\n",
    "    \"Sample ID given for sequencing\",\n",
    "    \"ENA Sample ID\",\n",
    "    \"GISAID Virus Name\",\n",
    "    \"GISAID id\",\n",
    "    \"Originating Laboratory\",\n",
    "    \"Submitting Institution\",\n",
    "    \"Sample Collection Date\",\n",
    "    \"Sample Received Date\",\n",
    "    \"Purpose of sampling\",\n",
    "    \"Biological Sample Storage Condition \",\n",
    "    \"Specimen source\",\n",
    "    \"Environmental Material\",\n",
    "    \"Environmental System\",\n",
    "    \"Collection Device\",\n",
    "    \"Host\",\n",
    "    \"Host Age\",\n",
    "    \"Host Gender\",\n",
    "    \"Sequencing Date\",\n",
    "    \"Rna Extraction Protocol\",\n",
    "    \"Commercial All-in-one library kit\",\n",
    "    \"Library Preparation Kit\",\n",
    "    \"Enrichment Protocol\",\n",
    "    \"If Enrichment Protocol. If Other,Specify\",\n",
    "    \"Enrichment panel/assay\",\n",
    "    \"If Enrichment panel/assay. If Other, Specify\",\n",
    "    \"Enrichment panel/assay version\",\n",
    "    \"Number Of Samples In Run\",\n",
    "    \"Runid\",\n",
    "    \"Sequencing Instrument Model\",\n",
    "    \"Flowcell Kit\",\n",
    "    \"Source material\",\n",
    "    \"Capture method\",\n",
    "    \"Sequencing technique\",\n",
    "    \"Library Layout\",\n",
    "    \"Gene Name 1\",\n",
    "    \"Diagnostic Pcr Ct Value 1\",\n",
    "    \"Gene Name 2\",\n",
    "    \"Diagnostic Pcr Ct Value-2\",\n",
    "    \"Analysis Authors\",\n",
    "    \"Author Submitter\",\n",
    "    \"Authors\",\n",
    "    \"Sequence file R1 fastq\",\n",
    "    \"Sequence file R2 fastq\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff15706",
   "metadata": {},
   "source": [
    "## ISCIII schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_dict_ISCIII = {\n",
    "    \"equivalences\" : {\"Public Health sample id\" : \"Código SiViEs\",\n",
    "                     \"Sample ID given by originating laboratory\" : \"Ref Hospital\",\n",
    "                     \"Sample ID given by the submitting laboratory\" : \"ID CNM\",\n",
    "                     \"Sample ID given in the microbiology lab\" : \"ID VI-VRP\",\n",
    "                     \"Sample ID given if multiple rna-extraction or passages\" : \"ID VI-VRP\",\n",
    "                     \"Sample ID given for sequencing\" : \"ID VI-VRP\",\n",
    "                     \"GISAID id\" : \"ID GISAID\",\n",
    "                     \"Originating Laboratory\" : \"Hospital\",\n",
    "                     \"Sample Collection Date\" : \"Fecha de toma \",\n",
    "                     \"Sample Received Date\" : \"Fecha recepción\",\n",
    "                     \"Host Age\" : \"Grupo edad\",\n",
    "                     \"Diagnostic Pcr Ct Value 1\" : \"PCR genE\",\n",
    "                     \"Sequencing Date\" : \"Fecha de secuenciación\",\n",
    "                     \"Rna Extraction Protocol\" : \"\"                     \n",
    "                    },\n",
    "    \"constants\" : {},\n",
    "    \"empty\" : [],\n",
    "    \"outer\" : { }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49cd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_dict_ISCIII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3929f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
